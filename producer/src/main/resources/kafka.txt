1.启动一个consumer时默认只从最新的消息偏移量(offset)接收消息，如果想从头开始消费需要设置from beginning
2.topic的消息都存在kafka-logs/主题-分区0/00000000.log。一个topic可以创建多个分区，防止单文件存储消息量过大，可以提高读写并发能力
3.在kafka-logs目录下默认有50个_consumer_offset_49分区文件。目的是为了分布式系统中，不同消费者组同时可以向broker提交消息消费偏移量，
提交定位是根据hash(consumerGroupId)%50。这个文件里记录了某个消费者组消费某个topic的消息消费偏移量
4.在集群环境创建topic时除了指定partition个数外还可以指定副本数量。每个分区都会创建相应数量的副本放在不同的broker上。
每个分区消息数据的所有副本中会有一个leader,生产者向leader发送消息，leader负责向其他副本同步数据，消费者向leader消费消息。
如果某个leader下线，则会重新选举leader
5.单播消息：一个消费者组里多个消费者同时订阅一个topic,但一条消息只能被一个消费者消费
6.多播消息：不同消费者组里的消费者订阅同一个topic里的消息，但每个消费者组里还是只能有一个消费者可以消费当前消息
7.当前消费者group，当前topic，当前partition的current-offset:7当前消息偏移量，已经消费的消息数。log-end-offset:11总的消息数量。lag:4积压的消息量
8.消息默认会被保存7天，之后会被删除
9.同一个消费者组内可以启动的消费者数量与topic的partition数相同，多出来的也消费不到消息，因为一个partition内消息只能被同一个group内的一个消费者消费。
但可以作为冗余服务以防某个消费者下线，提高系统可用性，（疑问：同一个partition内的消息是被一个固定消费者消费吗）但一个group内的一个consumer可以消费多个partition
10.集群中同一个partition内的消息可以保证顺序性消费，因为一个partition内消息只能被一个group内的一个消费者消费。